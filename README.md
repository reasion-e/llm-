# llm-é¢ç»
ðŸŸ¢ ä¸€é¢ï¼šåŸºç¡€ä¸Žå¾®è°ƒå®žæˆ˜1. å…«è‚¡ï¼šNLPå’ŒLLMæœ€å¤§çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿä¸¤è€…æœ‰ä½•å…±åŒå’Œä¸åŒä¹‹å¤„ï¼ŸåŒºåˆ«ï¼šèŒƒå¼ä¸åŒï¼šä¼ ç»ŸNLPé€šå¸¸æ˜¯â€œé¢„è®­ç»ƒ+ç‰¹å®šä»»åŠ¡å¾®è°ƒâ€æˆ–é’ˆå¯¹ç‰¹å®šä»»åŠ¡è®¾è®¡ç‰¹å®šæ¨¡åž‹ï¼ˆå¦‚åºåˆ—æ ‡æ³¨ç”¨CRFï¼Œåˆ†ç±»ç”¨BERTï¼‰ï¼›LLMåˆ™æ˜¯é€šç”¨ç”ŸæˆèŒƒå¼ï¼ˆNext Token Predictionï¼‰ï¼Œé€šè¿‡Prompt Engineeringæˆ–Instruction Tuningè§£å†³å„ç§ä»»åŠ¡ã€‚æ¶ŒçŽ°èƒ½åŠ›ï¼ˆEmergent Abilityï¼‰ï¼šLLMåœ¨å‚æ•°é‡çªç ´ä¸€å®šè§„æ¨¡ï¼ˆå¦‚10B+ï¼‰åŽï¼Œä¼šå‡ºçŽ°ä¼ ç»ŸNLPæ¨¡åž‹ä¸å…·å¤‡çš„æŽ¨ç†ã€ä»£ç ç”Ÿæˆã€ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆIn-Context Learningï¼‰èƒ½åŠ›ã€‚å…±åŒç‚¹ï¼šéƒ½åŸºäºŽç»Ÿè®¡è¯­è¨€æ¨¡åž‹ï¼Œä¸”ç›®å‰ä¸»æµéƒ½åŸºäºŽTransformeræž¶æž„ã€‚ä¸åŒç‚¹ï¼šå¤„ç†é•¿æ–‡æœ¬èƒ½åŠ›ã€æ³›åŒ–èƒ½åŠ›ã€å¯¹è®­ç»ƒç®—åŠ›çš„éœ€æ±‚é‡çº§å®Œå…¨ä¸åŒã€‚2. å…«è‚¡ï¼šæ¿€æ´»å‡½æ•°æœ‰äº†è§£å—ï¼Œä½ çŸ¥é“å“ªäº›LLMå¸¸ç”¨çš„æ¿€æ´»å‡½æ•°ï¼Ÿä¸ºä»€ä¹ˆé€‰ç”¨å®ƒï¼Ÿå¸¸ç”¨ï¼šGELU, Swish, SwiGLU (ç›®å‰LLama, Qwen, DeepSeekä¸»æµ)ã€‚ä¸ºä»€ä¹ˆé€‰SwiGLUï¼šç›¸æ¯”ReLUï¼Œå®ƒä»¬æ˜¯å…‰æ»‘çš„ï¼ˆéžé›¶æ¢¯åº¦ï¼‰ï¼Œæœ‰åŠ©äºŽè®­ç»ƒç¨³å®šæ€§ã€‚SwiGLUåœ¨GLUï¼ˆé—¨æŽ§çº¿æ€§å•å…ƒï¼‰çš„åŸºç¡€ä¸Šå¼•å…¥äº†Swishæ¿€æ´»ï¼Œå¢žåŠ äº†æ¨¡åž‹çš„éžçº¿æ€§è¡¨è¾¾èƒ½åŠ›ã€‚è™½ç„¶å¢žåŠ äº†å‚æ•°é‡ï¼ˆéœ€è¦ä¸‰ä¸ªæŠ•å½±çŸ©é˜µï¼‰ï¼Œä½†åœ¨åŒç­‰è®¡ç®—é‡ä¸‹æ•ˆæžœé€šå¸¸ä¼˜äºŽGELUã€‚3. å…«è‚¡ï¼šå¼€æºæ¡†æž¶äº†è§£è¿‡å“ªäº›ï¼ŸQwenï¼ŒDeepseekçš„è®ºæ–‡æ˜¯å¦æœ‰ç ”è¯»è¿‡ï¼Œè¯´ä¸€ä¸‹å…¶ä¸­çš„åˆ›æ–°ç‚¹ï¼ŸDeepSeek (V2/V3)ï¼šMLA (Multi-head Latent Attention)ï¼šè¿™æ˜¯æ ¸å¿ƒåˆ›æ–°ã€‚é€šè¿‡ä½Žç§©åŽ‹ç¼©KV Cacheï¼Œåœ¨ä¿æŒæŽ¨ç†æ€§èƒ½çš„åŒæ—¶å¤§å¹…å‡å°‘äº†æ˜¾å­˜å ç”¨ï¼ˆKV Cacheä¸å†æ˜¯ç“¶é¢ˆï¼‰ã€‚DeepSeek-MoEï¼šç»†ç²’åº¦ä¸“å®¶è®¾è®¡ï¼Œæ¿€æ´»æ›´å¤šçš„ç»†ç²’åº¦ä¸“å®¶ï¼Œæ—¢ä¿è¯äº†çŸ¥è¯†å¹¿åº¦åˆæŽ§åˆ¶äº†è®¡ç®—æˆæœ¬ã€‚Qwen (Qwen2/2.5)ï¼šé«˜è´¨é‡æ•°æ®æ¸…æ´—ï¼šQwençš„æŠ€æœ¯æŠ¥å‘Šå¼ºè°ƒäº†é¢„è®­ç»ƒæ•°æ®çš„è§„æ¨¡å’Œè´¨é‡ï¼Œç‰¹åˆ«æ˜¯ä»£ç å’Œæ•°å­¦æ•°æ®çš„é…æ¯”ã€‚GQA (Grouped Query Attention)ï¼šåœ¨æ‰€æœ‰å°ºå¯¸æ¨¡åž‹ä¸­æ™®åŠï¼ŒåŠ é€ŸæŽ¨ç†ã€‚Dual Chunk Attention (éƒ¨åˆ†ç‰ˆæœ¬)ï¼šè§£å†³é•¿æ–‡æœ¬æ³¨æ„åŠ›è¡°å‡é—®é¢˜ã€‚4. é¡¹ç›®ï¼šå¤§æ¨¡åž‹å¾®è°ƒæœ€é‡è¦çš„æ˜¯ä»€ä¹ˆï¼Ÿæ•°æ®è´¨é‡ï¼ˆData Qualityï¼‰æ˜¯ç¬¬ä¸€ä½çš„ã€‚Garbage In, Garbage Outã€‚æ•°æ®çš„å¤šæ ·æ€§ä¸Žåˆ†å¸ƒï¼šæŒ‡ä»¤çš„è¦†ç›–é¢è¦å¹¿ï¼Œé¿å…æ¨¡åž‹è¿‡æ‹Ÿåˆåˆ°å•ä¸€ç‰¹å®šæ ¼å¼ã€‚Prompt Templateçš„å¯¹é½ï¼šè®­ç»ƒæ—¶çš„Promptæ ¼å¼å¿…é¡»ä¸ŽæŽ¨ç†æ—¶ä¸¥æ ¼ä¸€è‡´ã€‚5. é¡¹ç›®ï¼šSFT+DPOè®­ç»ƒæ€Žä¹ˆç»„ç»‡è¿™éƒ¨åˆ†æ•°æ®çš„ï¼Ÿæ˜¯è‡ªå·±æž„é€ è¿˜æ˜¯ç”¨å…¬å¼€æ•°æ®ï¼ŸSFTï¼šé€šå¸¸é‡‡ç”¨ (Prompt, Response) æ ¼å¼ã€‚æ¥æºï¼šä¸šåŠ¡æ—¥å¿—æ¸…æ´—ã€GPT-4è’¸é¦ç”Ÿæˆã€å…¬å¼€æ•°æ®é›†ï¼ˆå¦‚Alpacaï¼‰ã€‚DPO (Direct Preference Optimization)ï¼šæ•°æ®æ ¼å¼ï¼š(Prompt, Chosen_Response, Rejected_Response)ã€‚æž„é€ æ–¹æ³•ï¼šè‡ªå·±æž„é€ ï¼šç”¨å½“å‰SFTæ¨¡åž‹å¯¹åŒä¸€ä¸ªPromptç”Ÿæˆå¤šä¸ªå›žå¤ï¼Œäººå·¥æˆ–ç”¨æ›´å¼ºæ¨¡åž‹ï¼ˆå¦‚GPT-4ä½œä¸ºJudgeï¼‰æ‰“åˆ†ï¼Œé«˜åˆ†é€‰ä¸ºChosenï¼Œä½Žåˆ†é€‰ä¸ºRejectedã€‚å…¬å¼€æ•°æ®ï¼šå¦‚HH-RLHF, UltraFeedbackã€‚å…³é”®ç‚¹ï¼šRejectedå›žå¤æœ€å¥½æ˜¯é«˜é”™è¯¯çŽ‡ä½†é€»è¾‘ä¼¼æ˜¯è€Œéžçš„â€œéš¾è´Ÿä¾‹â€ï¼Œæˆ–è€…æ˜¯æ¨¡åž‹å®¹æ˜“å‡ºçŽ°çš„å¹»è§‰/é‡å¤æ¨¡å¼ã€‚6. é¡¹ç›®ï¼šLoRAå¾®è°ƒæ€Žä¹ˆé€‰rankå€¼ï¼Ÿåˆå¹¶æƒé‡æœ‰æ²¡æœ‰é‡åˆ°æ¢¯åº¦çˆ†ç‚¸ï¼ŸRanké€‰æ‹©ï¼šé€šå¸¸è®¾ä¸º 8, 16, 32, 64ã€‚å¯¹äºŽç‰¹å®šä»»åŠ¡ï¼ˆå¦‚æ ¼å¼è½¬æ¢ï¼‰ï¼ŒRank=8å¯èƒ½å¤Ÿäº†ï¼›å¯¹äºŽéœ€è¦æ³¨å…¥æ–°çŸ¥è¯†ï¼ˆå¦‚æ–°é¢†åŸŸæœ¯è¯­ï¼‰ï¼Œå¯èƒ½éœ€è¦Rank=64ç”šè‡³æ›´é«˜ã€‚Alphaå€¼é€šå¸¸è®¾ä¸ºRankçš„2å€ã€‚æ¢¯åº¦/åˆå¹¶é—®é¢˜ï¼šåˆå¹¶æ—¶å¦‚æžœBase Modelæ˜¯FP16/INT4ï¼Œè€ŒAdapteræ˜¯FP32ï¼Œå¯èƒ½ä¼šæœ‰ç²¾åº¦æº¢å‡ºã€‚æ¢¯åº¦çˆ†ç‚¸ï¼šé€šå¸¸å‘ç”Ÿåœ¨å­¦ä¹ çŽ‡è¿‡å¤§æ—¶ã€‚LoRAå±‚åˆå§‹åŒ–é€šå¸¸ä¸º0ï¼Œè®­ç»ƒåˆæœŸè¾ƒç¨³ï¼Œå¦‚æžœçˆ†ç‚¸é€šå¸¸æ£€æŸ¥Warmup stepså’ŒLearning Rateã€‚7. é¡¹ç›®ï¼šLoRAåŽŸç†ï¼ŸLoRAæ˜¯ä¸æ˜¯åªèƒ½åœ¨Linearå±‚æ’ï¼Ÿä¸ºä»€ä¹ˆä¸èƒ½æ’åœ¨LayerNormä¹‹åŽï¼ŸåŽŸç†ï¼šå‡è®¾æ¨¡åž‹æ›´æ–°é‡ $\Delta W$ æ˜¯ä½Žç§©çš„ï¼Œå°†å…¶åˆ†è§£ä¸º $BA$ï¼Œå…¶ä¸­ $B \in R^{d \times r}, A \in R^{r \times d}$ï¼Œä¸” $r \ll d$ã€‚æ’å…¥ä½ç½®ï¼šä¸»è¦åœ¨ Linear å±‚ï¼ˆq_proj, v_proj, k_proj, o_proj, gate_proj, up_proj, down_projï¼‰ã€‚LayerNormï¼šLayerNormåŒ…å«çš„æ˜¯ç¼©æ”¾å› å­ï¼ˆScaleï¼‰å’Œåç§»é‡ï¼ˆShiftï¼‰ï¼Œå‚æ•°é‡æžå°ï¼ˆ$2d$ï¼‰ã€‚å¯¹è¿™äº›å‘é‡è¿›è¡Œä½Žç§©åˆ†è§£æ²¡æœ‰æ„ä¹‰ï¼ˆå‚æ•°åŽ‹ç¼©æ¯”ä¸é«˜ï¼‰ï¼Œä¸”LayerNormè´Ÿè´£ç‰¹å¾å½’ä¸€åŒ–ï¼Œå¯¹ç¨³å®šæ€§æžé‡è¦ï¼Œå¼ºè¡Œä½Žç§©å¹²æ‰°å®¹æ˜“å¯¼è‡´æ¨¡åž‹åå¡Œã€‚8. é¡¹ç›®ï¼šQLoRAæ˜¯æ€Žä¹ˆé™ä½Žèµ„æºæˆæœ¬çš„ï¼Ÿ4-bit NormalFloat (NF4)ï¼šä¸€ç§ä¿¡æ¯è®ºä¸Šæœ€ä¼˜çš„4bité‡åŒ–æ•°æ®ç±»åž‹ï¼Œæ¯”æ ‡å‡†INT4ç²¾åº¦æ›´é«˜ã€‚Double Quantizationï¼šå¯¹é‡åŒ–å¸¸æ•°å†æ¬¡è¿›è¡Œé‡åŒ–ï¼Œè¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜ã€‚Paged Optimizersï¼šåˆ©ç”¨CPUå†…å­˜æ¥å¤„ç†ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆOptimizer Statesï¼‰çš„æ˜¾å­˜å³°å€¼ï¼ˆOOMæ—¶è‡ªåŠ¨æ¢é¡µï¼‰ã€‚9. é¡¹ç›®ï¼šLLMæŽ¨ç†æ•ˆçŽ‡ï¼Œéƒ¨ç½²åˆ°åœ¨çº¿ç³»ç»Ÿæ€Žä¹ˆè§£å†³æ•ˆçŽ‡é—®é¢˜ï¼ŸæŠ€æœ¯æ ˆï¼švLLM, TensorRT-LLM, LMDeployã€‚æ ¸å¿ƒæŠ€æœ¯ï¼šContinuous Batchingï¼šè§£å†³è¯·æ±‚é•¿åº¦ä¸ä¸€å¯¼è‡´çš„Paddingæµªè´¹ã€‚PagedAttentionï¼šè§£å†³KV Cacheæ˜¾å­˜ç¢Žç‰‡åŒ–é—®é¢˜ã€‚é‡åŒ–ï¼šW8A8 æˆ– W4A16ï¼ˆæƒé‡4bitï¼Œæ¿€æ´»16bitï¼‰ã€‚æŠ•æœºé‡‡æ · (Speculative Decoding)ï¼šç”¨å°æ¨¡åž‹è‰æ‹Ÿtokenï¼Œå¤§æ¨¡åž‹éªŒè¯ã€‚10. é¡¹ç›®ï¼šæ¨¡åž‹è£å‰ªï¼ŸMambaæ›¿æ¢ï¼Ÿè£å‰ªï¼šç»“æž„åŒ–è£å‰ªï¼ˆå‰ªæŽ‰æŸäº›Attention Headæˆ–FFNå±‚ï¼‰ï¼Œéžç»“æž„åŒ–è£å‰ªï¼ˆç¨€ç–åŒ–ï¼‰ã€‚Mamba/SSMï¼šè¿™æ˜¯ä¸€ç§éžTransformeræž¶æž„ï¼ˆçº¿æ€§RNNï¼‰ã€‚å¦‚æžœå°è¯•è¿‡ï¼Œå¯ä»¥è¯´å°†Transformerçš„FFNéƒ¨åˆ†ä¿ç•™ï¼ŒAttentionéƒ¨åˆ†æ›¿æ¢ä¸ºMambaå—ï¼Œå®žçŽ°çº¿æ€§å¤æ‚åº¦æŽ¨ç†ï¼Œé€‚åˆè¶…é•¿æ–‡æœ¬ã€‚11. ä»£ç é¢˜ï¼šå®žçŽ°Casual Maskçš„MHAï¼Œè¯´ä¸‹å¤æ‚åº¦å¤æ‚åº¦ï¼š$O(N^2 \cdot d)$ï¼Œå› ä¸ºAttention Matrixæ˜¯ $N \times N$ã€‚æ ¸å¿ƒä»£ç é€»è¾‘ï¼šPythonimport torch
import torch.nn as nn
import torch.nn.functional as F
import math

class CausalSelfAttention(nn.Module):
    def __init__(self, d_model, n_head, max_len=1024):
        super().__init__()
        self.d_model = d_model
        self.n_head = n_head
        self.head_dim = d_model // n_head
        
        self.q_proj = nn.Linear(d_model, d_model)
        self.k_proj = nn.Linear(d_model, d_model)
        self.v_proj = nn.Linear(d_model, d_model)
        self.out_proj = nn.Linear(d_model, d_model)
        
        # æ³¨å†Œä¸€ä¸ªä¸‹ä¸‰è§’çŸ©é˜µä½œä¸ºmaskï¼Œä¸ä½œä¸ºå‚æ•°æ›´æ–°
        self.register_buffer("mask", torch.tril(torch.ones(max_len, max_len))
                                     .view(1, 1, max_len, max_len))

    def forward(self, x):
        B, T, C = x.shape
        # [B, T, n_head, head_dim] -> [B, n_head, T, head_dim]
        q = self.q_proj(x).view(B, T, self.n_head, self.head_dim).transpose(1, 2)
        k = self.k_proj(x).view(B, T, self.n_head, self.head_dim).transpose(1, 2)
        v = self.v_proj(x).view(B, T, self.n_head, self.head_dim).transpose(1, 2)

        # Attention Score: Q @ K^T / sqrt(d_k)
        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(self.head_dim))
        
        # Casual Masking: å°†ä¸Šä¸‰è§’ï¼ˆæœªæ¥çš„tokenï¼‰å¡«å……ä¸º -inf
        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))
        
        att = F.softmax(att, dim=-1)
        y = att @ v # [B, n_head, T, head_dim]
        
        y = y.transpose(1, 2).contiguous().view(B, T, C)
        return self.out_proj(y)
ðŸ”µ äºŒé¢ï¼šåŽŸç†ã€RAGä¸Žç³»ç»Ÿè®¾è®¡1. å…«è‚¡ï¼šTransformeråº•å±‚åŽŸç†ï¼Œä¸ºå•¥èƒ½æ›¿ä»£RNNï¼Ÿå¹¶è¡Œè®¡ç®—ï¼šRNNå¿…é¡»ç­‰å¾…å‰ä¸€ä¸ªæ—¶åˆ»è®¡ç®—å®Œï¼ˆæ—¶åºä¾èµ–ï¼‰ï¼ŒTransformeré€šè¿‡Self-Attentionå¯ä»¥åŒæ—¶è®¡ç®—åºåˆ—ä¸­æ‰€æœ‰tokençš„å…³ç³»ï¼Œè®­ç»ƒé€Ÿåº¦å¤§å¹…æå‡ã€‚é•¿è·ç¦»ä¾èµ–ï¼šRNNå­˜åœ¨æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ï¼Œé•¿è·ç¦»è®°å¿†èƒ½åŠ›å·®ã€‚Transformerä»»æ„ä¸¤ä¸ªtokenä¹‹é—´çš„è·ç¦»æ˜¯1ï¼Œèƒ½ç›´æŽ¥æ•èŽ·é•¿è·ç¦»å…³ç³»ã€‚2. å…«è‚¡ï¼šé¢„æµ‹tokençš„æŸå¤±æ€Žä¹ˆç®—ï¼Ÿå¸¸è§çš„æŸå¤±å‡½æ•°ï¼Ÿè®¡ç®—ï¼šæ¨¡åž‹è¾“å‡ºLogits [Batch, Seq_Len, Vocab_Size]ã€‚Shiftæ“ä½œï¼šInputæ˜¯ x[:-1]ï¼ŒTargetæ˜¯ x[1:]ã€‚å¯¹æ¯ä¸ªä½ç½®åšCross Entropy Lossã€‚å¸¸è§å‡½æ•°ï¼šCross Entropy (äº¤å‰ç†µ)ï¼šç»å¤§å¤šæ•°LLMé¢„è®­ç»ƒå’ŒSFTä½¿ç”¨ã€‚Focal Lossï¼šç”¨äºŽè§£å†³ç±»åˆ«ä¸å¹³è¡¡ï¼ˆä½†åœ¨LLMé¢„è®­ç»ƒä¸­ä¸å¸¸è§ï¼‰ã€‚Ranking Loss (Pairwise)ï¼šç”¨äºŽReward Modelè®­ç»ƒã€‚3. é¡¹ç›®ï¼šRAGå…¨é“¾è·¯åŠChunkåˆ‡åˆ†ï¼Ÿé“¾è·¯ï¼šæ–‡æ¡£è§£æž(PDF/Markdown) -> æ¸…æ´— -> Chunking -> Embedding -> å­˜å…¥VectorDB -> Query Rewrite -> æ£€ç´¢(TopK) -> Rerank -> LLMç”Ÿæˆã€‚Chunkåˆ‡åˆ†ï¼šå›ºå®šå­—ç¬¦æ•°ï¼šå¦‚512 tokensï¼Œoverlap 50ã€‚è¯­ä¹‰åˆ‡åˆ†ï¼šåŸºäºŽå¥å·ã€æ®µè½ï¼Œæˆ–ä½¿ç”¨NLPå·¥å…·ï¼ˆå¦‚NLTK/Spacyï¼‰æŒ‰è¯­ä¹‰è¾¹ç•Œåˆ‡åˆ†ã€‚é€’å½’åˆ‡åˆ† (RecursiveCharacterTextSplitter)ï¼šå…ˆæŒ‰æ®µè½åˆ‡ï¼Œå¤ªé•¿å†æŒ‰å¥å­åˆ‡ã€‚4. é¡¹ç›®ï¼šRAGæœ€å¤§ç“¶é¢ˆï¼Ÿæ€Žä¹ˆæå‡Recallï¼Ÿç“¶é¢ˆï¼šæ£€ç´¢ä¸åˆ°ï¼ˆRecallä½Žï¼‰æˆ– æ£€ç´¢åˆ°äº†ç”±äºŽåˆ‡åˆ†å¤ªç¢Žä¸¢å¤±ä¸Šä¸‹æ–‡ï¼ˆContextç¼ºå¤±ï¼‰ã€‚æå‡Recallï¼šHybrid Searchï¼šå‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ï¼‰ + BM25ï¼ˆå…³é”®è¯ï¼‰ã€‚Query Rewriteï¼šå°†ç”¨æˆ·é—®é¢˜æ”¹å†™ä¸ºæ›´é€‚åˆæ£€ç´¢çš„å½¢å¼ï¼ˆå¦‚æ‰©å±•åŒä¹‰è¯ï¼‰ã€‚Hypothetical Document Embeddings (HyDE)ï¼šå…ˆè®©LLMç”Ÿæˆä¸€ä¸ªå‡è®¾ç­”æ¡ˆï¼Œç”¨å‡è®¾ç­”æ¡ˆåŽ»æ£€ç´¢ã€‚Fine-tune Embedding Modelï¼šé’ˆå¯¹ç‰¹å®šé¢†åŸŸæ•°æ®å¾®è°ƒEmbeddingæ¨¡åž‹ã€‚5. é¡¹ç›®ï¼šGraphRAGåŽŸç†åŠéš¾ç‚¹ï¼Ÿå¢žé‡åœºæ™¯ï¼ŸåŽŸç†ï¼šåˆ©ç”¨LLMæå–å®žä½“å’Œå…³ç³»æž„å»ºçŸ¥è¯†å›¾è°±ã€‚æ£€ç´¢æ—¶ä¸ä»…é è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œè¿˜ä¾é å›¾çš„æ‹“æ‰‘ç»“æž„ï¼ˆç¤¾åŒºæ‘˜è¦ï¼‰ã€‚éš¾ç‚¹ï¼šæž„å»ºæˆæœ¬é«˜ï¼šéœ€è¦LLMå¤§é‡è°ƒç”¨æ¥æŠ½å–ä¸‰å…ƒç»„ã€‚ç¤¾åŒºæ£€æµ‹ï¼ˆCommunity Detectionï¼‰ï¼šLeidenç®—æ³•åœ¨å¤§è§„æ¨¡å›¾ä¸Šçš„è®¡ç®—å¼€é”€ã€‚å¢žé‡åœºæ™¯ï¼šæ–°æ–‡æ¡£è¿›æ¥ï¼Œéœ€è¦è¯†åˆ«æ–°å®žä½“å¹¶Mergeåˆ°æ—§å›¾è°±ä¸­ï¼Œå¦‚æžœæ¶‰åŠè·¨ç¤¾åŒºåˆå¹¶ï¼Œéœ€è¦å±€éƒ¨æ›´æ–°ç¤¾åŒºæ‘˜è¦ï¼Œå·¥ç¨‹å¤æ‚åº¦æžé«˜ã€‚6. é¡¹ç›®ï¼šçŸ¥è¯†åº“åŠ¨æ€å¢žé‡æ›´æ–°ï¼Œé¿å…åˆ†å¸ƒä¸ä¸€è‡´ï¼Ÿé—®é¢˜ï¼šæ—§æ–‡æ¡£åˆ†å—ç­–ç•¥æˆ–Embeddingæ¨¡åž‹å¯èƒ½ä¸Žæ–°æ–‡æ¡£ä¸ä¸€è‡´ã€‚è§£å†³ï¼šç‰ˆæœ¬æŽ§åˆ¶ï¼šä¸ºä¸åŒæ‰¹æ¬¡çš„æ•°æ®æ‰“Tagï¼Œæ£€ç´¢æ—¶åŠ Filterã€‚æ»‘åŠ¨çª—å£/é‡æž„ï¼šæœ€ç¨³å¦¥ä½†æ˜‚è´µçš„æ˜¯å®šæœŸå…¨é‡é‡å»ºç´¢å¼•ã€‚ä¸€è‡´æ€§ç­–ç•¥ï¼šä¿æŒChunk Sizeå’ŒOverlapå‚æ•°ä¸å˜ï¼Œä¸è½»æ˜“æ›´æ¢Embeddingæ¨¡åž‹ã€‚7. é¡¹ç›®ï¼šRAGè¯„ä¼°ä½“ç³»ï¼ŸRAGASæ¡†æž¶ï¼šFaithfulness (å¿ å®žåº¦)ï¼šç­”æ¡ˆæ˜¯å¦ç”±æ£€ç´¢å†…å®¹æŽ¨å¯¼å‡ºæ¥ï¼ˆé˜²å¹»è§‰ï¼‰ã€‚Answer Relevanceï¼šç­”æ¡ˆæ˜¯å¦å›žç­”äº†ç”¨æˆ·é—®é¢˜ã€‚Context Recallï¼šæ£€ç´¢å†…å®¹æ˜¯å¦åŒ…å«äº†æ­£ç¡®ç­”æ¡ˆæ‰€éœ€çš„ä¿¡æ¯ã€‚8. é¡¹ç›®ï¼šQLoRAä¸ºä»€ä¹ˆé€‰NF4å’ŒFP16ï¼ŸNF4çš„åˆ†å¸ƒæ‹Ÿåˆé€»è¾‘ï¼ŸNF4é€»è¾‘ï¼šé¢„è®­ç»ƒæƒé‡çš„åˆ†å¸ƒé€šå¸¸æœä»Žä»¥0ä¸ºä¸­å¿ƒçš„æ­£æ€åˆ†å¸ƒã€‚NF4æ ¹æ®æ­£æ€åˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰åˆ’åˆ†åˆ†ä½æ•°ï¼ˆQuantilesï¼‰ï¼Œä½¿å¾—æ¯ä¸ªbiné‡Œçš„æ•°å€¼æ•°é‡å¤§è‡´ç›¸ç­‰ï¼Œä»Žè€Œå®žçŽ°ä¿¡æ¯é‡æœ€å¤§åŒ–ï¼ˆç†µæœ€å¤§åŒ–ï¼‰ã€‚ç»„åˆåŽŸå› ï¼šè®¡ç®—æ—¶éœ€è¦åé‡åŒ–å›žBF16/FP16è¿›è¡ŒçŸ©é˜µä¹˜æ³•ã€‚NF4ç”¨äºŽå­˜å‚¨ä»¥èŠ‚çœæ˜¾å­˜ï¼ŒFP16/BF16ç”¨äºŽè®¡ç®—ä»¥ä¿è¯æ¢¯åº¦ç²¾åº¦ã€‚9. é¡¹ç›®ï¼šæ¨¡åž‹éƒ¨ç½²å‚æ•°é‡å’Œç¡¬ä»¶å…³ç³»ï¼Ÿæ˜¾å­˜éœ€æ±‚ $\approx$ å‚æ•°é‡ $\times$ ç²¾åº¦å­—èŠ‚æ•° + KV Cache + æ¿€æ´»å€¼ã€‚FP16: 2 Bytes/paramã€‚INT8: 1 Byte/paramã€‚INT4: 0.5 Byte/paramã€‚å¸¦å®½ï¼ˆBandwidthï¼‰ï¼šå†³å®šäº†æŽ¨ç†é€Ÿåº¦ï¼ˆToken/sï¼‰ï¼Œå°¤å…¶æ˜¯Decodingé˜¶æ®µæ˜¯Memory-boundã€‚10. é¡¹ç›®ï¼šéƒ¨ç½²ä¸€ä¸ªMOEæž¶æž„ï¼ˆ235Bï¼Œåƒåˆ†ä¸‰æ¿€æ´»ï¼‰éœ€è¦å¤šå°‘ç®—åŠ›ï¼Ÿæ˜¾å­˜ï¼ˆVRAMï¼‰ï¼šå¿…é¡»å­˜ä¸‹æ‰€æœ‰ä¸“å®¶æƒé‡ã€‚235B $\times$ 2 Bytes (FP16) $\approx$ 470 GBã€‚è‡³å°‘éœ€è¦ 6-8 å¼  80GB A100/H800ã€‚ç®—åŠ›ï¼ˆComputeï¼‰ï¼šæŽ¨ç†æ—¶åªæ¿€æ´»éƒ¨åˆ†å‚æ•°ï¼ˆå¦‚3/1000ï¼‰ã€‚å®žé™…è®¡ç®—é‡ç›¸å½“äºŽä¸€ä¸ªå‡ Bæˆ–åå‡ Bçš„å°æ¨¡åž‹ã€‚æ‰€ä»¥å»¶è¿Ÿï¼ˆLatencyï¼‰å¾ˆä½Žï¼Œä½†æ˜¾å­˜ï¼ˆMemoryï¼‰éœ€æ±‚å¾ˆé«˜ã€‚11. ä»£ç é¢˜ï¼šlc54. èžºæ—‹çŸ©é˜µPythonclass Solution:
    def spiralOrder(self, matrix: List[List[int]]) -> List[int]:
        if not matrix: return []
        
        res = []
        top, bottom = 0, len(matrix) - 1
        left, right = 0, len(matrix[0]) - 1
        
        while top <= bottom and left <= right:
            # 1. Left -> Right
            for i in range(left, right + 1):
                res.append(matrix[top][i])
            top += 1
            
            # 2. Top -> Bottom
            for i in range(top, bottom + 1):
                res.append(matrix[i][right])
            right -= 1
            
            if top <= bottom:
                # 3. Right -> Left
                for i in range(right, left - 1, -1):
                    res.append(matrix[bottom][i])
                bottom -= 1
            
            if left <= right:
                # 4. Bottom -> Top
                for i in range(bottom, top - 1, -1):
                    res.append(matrix[i][left])
                left += 1
                
        return res
